#!/usr/bin/env python3
"""
ç„¼æ´¥å¸‚APIã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®èªè¨¼ã‚’ä½¿ç”¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã€ã‚«ã‚¿ãƒ­ã‚°å†…ã®ã™ã¹ã¦ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

import asyncio
import base64
import json
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Set
from urllib.parse import urljoin, urlparse

import aiohttp
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
BASE_URL = "https://city-api-catalog.smartcity-pf.com/yaizu"
API_BASE_URL = "https://city-api-catalog-api.smartcity-pf.com/yaizu"
DATA_DIR = Path("data/documentation")

# èªè¨¼æƒ…å ±
EMAIL = os.getenv("YAIZU_API_EMAIL")
PASSWORD = os.getenv("YAIZU_API_PASSWORD")


class CatalogPDFDownloader:
    """APIã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.email = EMAIL
        self.password = PASSWORD
        self.base_url = BASE_URL
        self.api_base_url = API_BASE_URL
        self.data_dir = DATA_DIR
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.session: Optional[aiohttp.ClientSession] = None
        self.auth_headers: Dict[str, str] = {}
        self.is_authenticated = False
        self.pdf_urls: Set[str] = set()
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def login(self) -> bool:
        """ã‚«ã‚¿ãƒ­ã‚°ã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³"""
        if not self.email or not self.password:
            print("âŒ èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        print(f"ğŸ“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {self.email}")
        
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–å¾—
            async with self.session.get(self.base_url) as response:
                print(f"  åˆæœŸã‚¢ã‚¯ã‚»ã‚¹: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ {response.status}")
            
            # Basicèªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã®ä½œæˆ
            credentials = f"{self.email}:{self.password}"
            encoded_credentials = base64.b64encode(credentials.encode()).decode()
            self.auth_headers = {
                "Authorization": f"Basic {encoded_credentials}",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
            }
            
            # èªè¨¼ä»˜ãã§ã‚¢ã‚¯ã‚»ã‚¹
            async with self.session.get(
                f"{self.base_url}/documentation",
                headers=self.auth_headers
            ) as response:
                print(f"  èªè¨¼å¿œç­”: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ {response.status}")
                if response.status == 200:
                    self.is_authenticated = True
                    print("âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                    return True
                else:
                    print(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ {response.status}")
                    return False
                    
        except Exception as e:
            print(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def find_pdf_urls(self) -> List[str]:
        """ã‚«ã‚¿ãƒ­ã‚°ãƒšãƒ¼ã‚¸ã‹ã‚‰PDFã®URLã‚’æ¢ç´¢"""
        if not self.is_authenticated:
            print("âŒ å…ˆã«ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")
            return []
        
        print("\nğŸ” PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢ä¸­...")
        
        # æ¢ç´¢ã™ã‚‹ãƒšãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
        pages_to_check = [
            "",
            "/documentation",
            "/catalog",
            "/specs",
            "/api-docs"
        ]
        
        for page_path in pages_to_check:
            url = f"{self.base_url}{page_path}"
            print(f"  ğŸ“„ ãƒã‚§ãƒƒã‚¯ä¸­: {url}")
            
            try:
                async with self.session.get(url, headers=self.auth_headers) as response:
                    if response.status != 200:
                        print(f"    ã‚¹ã‚­ãƒƒãƒ—: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ {response.status}")
                        continue
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'lxml')
                    
                    # PDFãƒªãƒ³ã‚¯ã‚’æ¢ã™
                    pdf_links = []
                    
                    # ç›´æ¥çš„ãªPDFãƒªãƒ³ã‚¯
                    for link in soup.find_all('a', href=True):
                        href = link['href']
                        if href.lower().endswith('.pdf'):
                            pdf_links.append(href)
                        elif 'pdf' in href.lower() or 'document' in href.lower():
                            pdf_links.append(href)
                    
                    # iframeã‚„embedã‚¿ã‚°å†…ã®PDF
                    for tag in soup.find_all(['iframe', 'embed', 'object']):
                        src = tag.get('src') or tag.get('data')
                        if src and '.pdf' in src.lower():
                            pdf_links.append(src)
                    
                    # JavaScriptã‹ã‚‰æŠ½å‡º
                    for script in soup.find_all('script'):
                        if script.string:
                            # PDFã®URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                            pdf_patterns = re.findall(r'["\'](.*?\.pdf[^"\']*)["\']', script.string, re.IGNORECASE)
                            pdf_links.extend(pdf_patterns)
                    
                    # APIä»•æ§˜æ›¸ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™ï¼ˆKong Developer Portalç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                    for spec_link in soup.find_all(['a', 'button'], class_=re.compile(r'spec|download|documentation')):
                        if 'href' in spec_link.attrs:
                            pdf_links.append(spec_link['href'])
                    
                    # è¦‹ã¤ã‹ã£ãŸãƒªãƒ³ã‚¯ã‚’å‡¦ç†
                    for link in pdf_links:
                        if not link.startswith('http'):
                            link = urljoin(url, link)
                        self.pdf_urls.add(link)
                    
                    print(f"    âœ“ {len(pdf_links)} å€‹ã®ãƒªãƒ³ã‚¯ã‚’ç™ºè¦‹")
                    
            except Exception as e:
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # APIä»•æ§˜æ›¸ã‚’ç›´æ¥ãƒã‚§ãƒƒã‚¯
        await self._check_api_specs()
        
        pdf_list = list(self.pdf_urls)
        print(f"\nğŸ“Š åˆè¨ˆ {len(pdf_list)} å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
        
        return pdf_list
    
    async def _check_api_specs(self):
        """APIä»•æ§˜æ›¸ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        print("  ğŸ” APIä»•æ§˜æ›¸ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        # Kong Developer Portalã®ä¸€èˆ¬çš„ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        spec_endpoints = [
            f"{self.api_base_url}/specs",
            f"{self.api_base_url}/documentation",
            f"{self.base_url}/specs",
            f"{self.base_url}/api/specs"
        ]
        
        for endpoint in spec_endpoints:
            try:
                async with self.session.get(endpoint, headers=self.auth_headers) as response:
                    if response.status == 200:
                        content_type = response.headers.get('content-type', '')
                        
                        # PDFãƒ¬ã‚¹ãƒãƒ³ã‚¹
                        if 'application/pdf' in content_type:
                            self.pdf_urls.add(endpoint)
                            print(f"    âœ“ PDFç™ºè¦‹: {endpoint}")
                        
                        # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
                        elif 'application/json' in content_type:
                            data = await response.json()
                            if isinstance(data, list):
                                for item in data:
                                    if isinstance(item, dict):
                                        # PDFã®URLã‚’æ¢ã™
                                        for key in ['url', 'download_url', 'pdf_url', 'spec_url']:
                                            if key in item and '.pdf' in str(item[key]).lower():
                                                self.pdf_urls.add(item[key])
                        
                        # HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹
                        else:
                            html = await response.text()
                            # OpenAPIã‚„Swaggerä»•æ§˜æ›¸ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                            spec_patterns = re.findall(r'["\'](/[^"\']*?(?:openapi|swagger|spec)[^"\']*?\.(?:pdf|json|yaml)[^"\']*)["\']', html, re.IGNORECASE)
                            for pattern in spec_patterns:
                                if pattern.endswith('.pdf'):
                                    full_url = urljoin(endpoint, pattern)
                                    self.pdf_urls.add(full_url)
            
            except Exception as e:
                continue
    
    async def download_pdf(self, url: str, filename: Optional[str] = None) -> bool:
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š
            if not filename:
                # URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                parsed_url = urlparse(url)
                filename = os.path.basename(parsed_url.path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã¾ãŸã¯æ‹¡å¼µå­ãŒãªã„å ´åˆ
                if not filename or not filename.endswith('.pdf'):
                    # URLã®ãƒãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                    import hashlib
                    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
                    filename = f"document_{url_hash}.pdf"
            
            filepath = self.data_dir / filename
            
            # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
            if filepath.exists():
                print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ï¼‰: {filename}")
                return True
            
            print(f"  ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {filename}")
            print(f"     URL: {url}")
            
            async with self.session.get(url, headers=self.auth_headers) as response:
                if response.status == 200:
                    content = await response.read()
                    
                    # PDFã‹ã©ã†ã‹ç¢ºèª
                    if content[:4] == b'%PDF':
                        with open(filepath, 'wb') as f:
                            f.write(content)
                        print(f"  âœ… ä¿å­˜å®Œäº†: {filepath}")
                        return True
                    else:
                        print(f"  âš ï¸  PDFã§ã¯ã‚ã‚Šã¾ã›ã‚“: {filename}")
                        return False
                else:
                    print(f"  âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ {response.status}")
                    return False
                    
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def download_all_pdfs(self) -> Dict[str, int]:
        """ã™ã¹ã¦ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        # ãƒ­ã‚°ã‚¤ãƒ³
        if not await self.login():
            return {"total": 0, "success": 0, "failed": 0}
        
        # PDFã®URLã‚’æ¢ç´¢
        pdf_urls = await self.find_pdf_urls()
        
        if not pdf_urls:
            print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {"total": 0, "success": 0, "failed": 0}
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        print(f"\nğŸ“¦ {len(pdf_urls)} å€‹ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
        
        results = {"total": len(pdf_urls), "success": 0, "failed": 0}
        
        for i, url in enumerate(pdf_urls, 1):
            print(f"\n[{i}/{len(pdf_urls)}]")
            if await self.download_pdf(url):
                results["success"] += 1
            else:
                results["failed"] += 1
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            await asyncio.sleep(0.5)
        
        return results


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 50)
    print("ç„¼æ´¥å¸‚APIã‚«ã‚¿ãƒ­ã‚° PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")
    print("=" * 50)
    
    async with CatalogPDFDownloader() as downloader:
        results = await downloader.download_all_pdfs()
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        print(f"  åˆè¨ˆ: {results['total']} ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"  æˆåŠŸ: {results['success']} ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"  å¤±æ•—: {results['failed']} ãƒ•ã‚¡ã‚¤ãƒ«")
        print("=" * 50)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        pdf_files = list(DATA_DIR.glob("*.pdf"))
        if pdf_files:
            print(f"\nğŸ“ {DATA_DIR} ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
            for pdf_file in sorted(pdf_files):
                size_mb = pdf_file.stat().st_size / (1024 * 1024)
                print(f"  - {pdf_file.name} ({size_mb:.2f} MB)")


if __name__ == "__main__":
    asyncio.run(main())