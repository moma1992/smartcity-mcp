#!/usr/bin/env python3
"""
ç„¼æ´¥å¸‚é˜²ç½é–¢é€£APIã‚«ã‚¿ãƒ­ã‚°ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
"""

import asyncio
import json
import os
from datetime import datetime
from pathlib import Path
import aiohttp
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

async def scrape_disaster_apis():
    """é˜²ç½é–¢é€£APIã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    
    # é˜²ç½é–¢é€£APIã®ã‚«ã‚¿ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
    disaster_apis = {
        "title": "ç„¼æ´¥å¸‚é˜²ç½é–¢é€£API",
        "description": "ç„¼æ´¥å¸‚ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§æä¾›ã•ã‚Œã‚‹é˜²ç½ãƒ»ç½å®³å¯¾ç­–é–¢é€£ã®API",
        "last_updated": datetime.now().isoformat(),
        "apis": []
    }
    
    # APIã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹
    api_key = os.getenv('YAIZU_API_KEY')
    headers = {
        "X-API-Key": api_key,
        "Accept": "text/html,application/json",
        "User-Agent": "Mozilla/5.0 (compatible; YaizuMCPScraper/1.0)"
    }
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡URL
    catalog_urls = [
        "https://city-api-catalog.smartcity-pf.com/yaizu/catalog",
        "https://city-api-catalog.smartcity-pf.com/yaizu",
    ]
    
    async with aiohttp.ClientSession() as session:
        for catalog_url in catalog_urls:
            print(f"ğŸ“¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: {catalog_url}")
            
            try:
                async with session.get(catalog_url, headers=headers, timeout=30) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # APIã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰é˜²ç½é–¢é€£ã®æƒ…å ±ã‚’æ¢ã™
                        # æ§˜ã€…ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§é˜²ç½é–¢é€£APIã‚’æ¤œç´¢
                        
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚«ãƒ¼ãƒ‰å½¢å¼ã®APIä¸€è¦§
                        api_cards = soup.find_all(['div', 'article'], class_=['api-card', 'api-item', 'catalog-item'])
                        for card in api_cards:
                            title_elem = card.find(['h2', 'h3', 'h4', 'a'])
                            if title_elem:
                                title = title_elem.get_text(strip=True)
                                # é˜²ç½é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                                if any(keyword in title for keyword in ['é˜²ç½', 'ç½å®³', 'é¿é›£', 'è­¦å ±', 'ãƒã‚¶ãƒ¼ãƒ‰', 'åœ°éœ‡', 'æ´¥æ³¢', 'å°é¢¨', 'å®‰å…¨']):
                                    api_info = extract_api_info(card, title)
                                    if api_info:
                                        disaster_apis['apis'].append(api_info)
                        
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã®APIä¸€è¦§
                        tables = soup.find_all('table')
                        for table in tables:
                            rows = table.find_all('tr')
                            for row in rows:
                                cells = row.find_all(['td', 'th'])
                                row_text = ' '.join([cell.get_text(strip=True) for cell in cells])
                                if any(keyword in row_text for keyword in ['é˜²ç½', 'ç½å®³', 'é¿é›£', 'è­¦å ±']):
                                    api_info = extract_api_from_row(row)
                                    if api_info:
                                        disaster_apis['apis'].append(api_info)
                        
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒªã‚¹ãƒˆå½¢å¼
                        lists = soup.find_all(['ul', 'ol'])
                        for lst in lists:
                            items = lst.find_all('li')
                            for item in items:
                                item_text = item.get_text(strip=True)
                                if any(keyword in item_text for keyword in ['é˜²ç½', 'ç½å®³', 'é¿é›£', 'è­¦å ±']):
                                    api_info = extract_api_from_list_item(item)
                                    if api_info:
                                        disaster_apis['apis'].append(api_info)
                        
                        print(f"âœ… {len(disaster_apis['apis'])}å€‹ã®é˜²ç½é–¢é€£APIã‚’æ¤œå‡º")
                        
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å®Ÿéš›ã®é˜²ç½é–¢é€£APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ¨å®šï¼‰
    # ç„¼æ´¥å¸‚ã®ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§æä¾›ã•ã‚Œã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹API
    estimated_apis = [
        {
            "name": "é¿é›£æ‰€æƒ…å ±API",
            "description": "ç„¼æ´¥å¸‚å†…ã®é¿é›£æ‰€ã®ä½ç½®ã€åå®¹äººæ•°ã€é–‹è¨­çŠ¶æ³ãªã©ã‚’æä¾›",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/shelters",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "status", "type": "string", "description": "é–‹è¨­çŠ¶æ³(open/closed/all)"},
                {"name": "area", "type": "string", "description": "åœ°åŒºå"},
                {"name": "limit", "type": "integer", "description": "å–å¾—ä»¶æ•°"}
            ],
            "response_example": {
                "shelters": [
                    {
                        "id": "shelter_001",
                        "name": "ç„¼æ´¥å¸‚ç«‹å¤§äº•å·ä¸­å­¦æ ¡",
                        "address": "ç„¼æ´¥å¸‚å¤§äº•å·...",
                        "capacity": 500,
                        "current_occupancy": 0,
                        "status": "closed",
                        "coordinates": {"lat": 34.8667, "lon": 138.3167}
                    }
                ]
            }
        },
        {
            "name": "ç½å®³è­¦å ±ãƒ»æ³¨æ„å ±API",
            "description": "æ°—è±¡åºã‹ã‚‰ç™ºè¡¨ã•ã‚Œã‚‹è­¦å ±ãƒ»æ³¨æ„å ±æƒ…å ±ã‚’æä¾›",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/alerts",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "type", "type": "string", "description": "è­¦å ±ç¨®åˆ¥"},
                {"name": "active", "type": "boolean", "description": "æœ‰åŠ¹ãªè­¦å ±ã®ã¿"}
            ],
            "response_example": {
                "alerts": [
                    {
                        "id": "alert_20240101_001",
                        "type": "å¤§é›¨è­¦å ±",
                        "level": "warning",
                        "issued_at": "2024-01-01T10:00:00Z",
                        "areas": ["ç„¼æ´¥å¸‚å…¨åŸŸ"],
                        "description": "å¤§é›¨ã«ã‚ˆã‚‹åœŸç ‚ç½å®³ã«è­¦æˆ’ã—ã¦ãã ã•ã„"
                    }
                ]
            }
        },
        {
            "name": "ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—API",
            "description": "æ´¥æ³¢ã€æ´ªæ°´ã€åœŸç ‚ç½å®³ç­‰ã®ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/hazardmap",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "type", "type": "string", "description": "ãƒã‚¶ãƒ¼ãƒ‰ç¨®åˆ¥(tsunami/flood/landslide)"},
                {"name": "lat", "type": "number", "description": "ç·¯åº¦"},
                {"name": "lon", "type": "number", "description": "çµŒåº¦"},
                {"name": "radius", "type": "number", "description": "æ¤œç´¢åŠå¾„(m)"}
            ],
            "response_example": {
                "hazard_areas": [
                    {
                        "type": "tsunami",
                        "risk_level": "high",
                        "expected_depth": "2-5m",
                        "evacuation_required": True,
                        "nearest_shelter": "shelter_001"
                    }
                ]
            }
        },
        {
            "name": "é˜²ç½ç„¡ç·šæ”¾é€API",
            "description": "é˜²ç½è¡Œæ”¿ç„¡ç·šã®æ”¾é€å†…å®¹ã‚’å–å¾—",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/broadcasts",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "date", "type": "string", "description": "æ—¥ä»˜(YYYY-MM-DD)"},
                {"name": "limit", "type": "integer", "description": "å–å¾—ä»¶æ•°"}
            ],
            "response_example": {
                "broadcasts": [
                    {
                        "id": "broadcast_001",
                        "timestamp": "2024-01-01T15:00:00Z",
                        "title": "é˜²ç½è¨“ç·´ã®ãŠçŸ¥ã‚‰ã›",
                        "content": "æœ¬æ—¥åˆå¾Œ3æ™‚ã‚ˆã‚Šã€å¸‚å†…å…¨åŸŸã§é˜²ç½è¨“ç·´ã‚’å®Ÿæ–½ã—ã¾ã™",
                        "priority": "normal"
                    }
                ]
            }
        },
        {
            "name": "æ²³å·æ°´ä½æƒ…å ±API",
            "description": "å¸‚å†…æ²³å·ã®æ°´ä½ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/water-levels",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "river", "type": "string", "description": "æ²³å·å"},
                {"name": "station", "type": "string", "description": "è¦³æ¸¬æ‰€ID"}
            ],
            "response_example": {
                "water_levels": [
                    {
                        "station_id": "station_001",
                        "station_name": "å¤§äº•å·æ©‹è¦³æ¸¬æ‰€",
                        "river": "å¤§äº•å·",
                        "current_level": 1.5,
                        "warning_level": 3.0,
                        "danger_level": 4.0,
                        "updated_at": "2024-01-01T15:30:00Z"
                    }
                ]
            }
        },
        {
            "name": "åœ°éœ‡æƒ…å ±API",
            "description": "åœ°éœ‡ç™ºç”Ÿæƒ…å ±ã¨éœ‡åº¦æƒ…å ±ã‚’æä¾›",
            "endpoint": "https://api.smartcity-yaizu.jp/v1/disaster/earthquakes",
            "method": "GET",
            "category": "é˜²ç½",
            "parameters": [
                {"name": "from", "type": "string", "description": "é–‹å§‹æ—¥æ™‚"},
                {"name": "to", "type": "string", "description": "çµ‚äº†æ—¥æ™‚"},
                {"name": "min_magnitude", "type": "number", "description": "æœ€å°ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰"}
            ],
            "response_example": {
                "earthquakes": [
                    {
                        "id": "eq_20240101_001",
                        "occurred_at": "2024-01-01T12:00:00Z",
                        "magnitude": 4.5,
                        "depth": "10km",
                        "epicenter": "é§¿æ²³æ¹¾",
                        "intensity_yaizu": "éœ‡åº¦3",
                        "tsunami_risk": False
                    }
                ]
            }
        }
    ]
    
    # æ¨å®šAPIã‚’è¿½åŠ 
    disaster_apis['apis'].extend(estimated_apis)
    
    # é‡è¤‡ã‚’å‰Šé™¤
    unique_apis = []
    seen_names = set()
    for api in disaster_apis['apis']:
        if api['name'] not in seen_names:
            unique_apis.append(api)
            seen_names.add(api['name'])
    
    disaster_apis['apis'] = unique_apis
    disaster_apis['total_count'] = len(unique_apis)
    
    return disaster_apis

def extract_api_info(element, title):
    """HTMLè¦ç´ ã‹ã‚‰APIæƒ…å ±ã‚’æŠ½å‡º"""
    api_info = {
        "name": title,
        "description": "",
        "category": "é˜²ç½",
        "endpoint": "",
        "method": "GET"
    }
    
    # èª¬æ˜æ–‡ã‚’æ¢ã™
    desc_elem = element.find(['p', 'div'], class_=['description', 'desc', 'summary'])
    if desc_elem:
        api_info['description'] = desc_elem.get_text(strip=True)
    
    # URLã‚’æ¢ã™
    url_elem = element.find('a', href=True)
    if url_elem:
        api_info['endpoint'] = url_elem['href']
    
    return api_info if api_info['name'] else None

def extract_api_from_row(row):
    """ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‹ã‚‰APIæƒ…å ±ã‚’æŠ½å‡º"""
    cells = row.find_all(['td', 'th'])
    if len(cells) >= 2:
        return {
            "name": cells[0].get_text(strip=True),
            "description": cells[1].get_text(strip=True) if len(cells) > 1 else "",
            "category": "é˜²ç½",
            "endpoint": "",
            "method": "GET"
        }
    return None

def extract_api_from_list_item(item):
    """ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰APIæƒ…å ±ã‚’æŠ½å‡º"""
    text = item.get_text(strip=True)
    link = item.find('a', href=True)
    
    return {
        "name": text.split('-')[0].strip() if '-' in text else text[:50],
        "description": text,
        "category": "é˜²ç½",
        "endpoint": link['href'] if link else "",
        "method": "GET"
    }

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ç„¼æ´¥å¸‚é˜²ç½é–¢é€£API ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
    print("=" * 60)
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    disaster_apis = await scrape_disaster_apis()
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_dir = Path("data/api_specs")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / "disaster_apis_catalog.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(disaster_apis, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… é˜²ç½é–¢é€£APIã‚«ã‚¿ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print(f"   ğŸ“„ {output_file}")
    print(f"   ğŸ“Š APIæ•°: {disaster_apis['total_count']}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\nğŸ“‹ é˜²ç½é–¢é€£APIä¸€è¦§:")
    print("-" * 40)
    for api in disaster_apis['apis']:
        print(f"â€¢ {api['name']}")
        if api['description']:
            print(f"  â”” {api['description'][:80]}...")
        if api.get('endpoint'):
            print(f"  â”” {api['endpoint']}")
    
    return disaster_apis

if __name__ == "__main__":
    asyncio.run(main())